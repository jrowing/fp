<%
  require "./scripts/eruby_util.rb"
%>

<%
  chapter(
    '01',
    %q{Scalars and vectors},
    'ch:vectors'
  )
%>

<% begin_sec("Continuity in nature",nil,'continuity-in-nature') %>

Ancient philosophers like Heraclitus and Parmenides quarreled over whether change
was real or only an illusion. Heraclitus was the one who famously said that you can't
step in the same river twice. From a modern perspective, a more interesting question
is whether change can be discontinuous. Leibniz claimed, less famously,
that ``nature never jumps,'' and his assertion has held up surprisingly well through
multiple revolutions in physics. 

<% marg(30) %>
<%
  fig(
    'leibniz-portrait',
    %q{Gottfried Wilhelm Leibniz (1646-1716) was a philosopher and one of the co-inventors of the calculus.}
  )
%>
<% end_marg %>

One of these revolutions was the discovery of quantum
mechanics, and you've probably heard the phrase ``quantum leap.'' Quantum leaps are not
actually leaps at all. For example, when an atomic nucleus undergoes radioactive decay,
it doesn't leap from state A to state B. If we prepare it in state A, then it gradually
transforms itself into a mixture of A and B, with the strength of the A part decaying exponentially,
while B gets correspondingly stronger. This mixture can be interpreted in probabilistic terms,
with the probability of A going down while B's goes up. So although Leibniz died a couple of
centuries too early to have had any inkling of quantum mechanics, he ended up being undeservedly correct.

To make these ideas about continuity more rigorous, we start by making everything
into a set. This would have upset Leibniz, who was sincerely convinced that
``a point may not be considered a part of a line,'' but the point-set approach is how the modern mathematician
thinks about these things by default.\footnote{An alternative description, which would have
been more to Leibniz's liking, is given
by smooth infinitesimal analysis, described, e.g., in Bell, \emph{A primer of infinitesimal analysis}.}
In this approach, a set contains points, and a point may be, for example:
%
\begin{itemize}
\item a point in Euclidean space,
\item an event in spacetime, or
\item a state of a physical system such as a machine or a gas of helium atoms.
\end{itemize}
%
An idealized particle has zero size, so Euclidean space can be thought of as the set of all possible locations
of a particle. The prototypical example of an event in spacetime would be the collision of two particles,
which happens at a certain location in space and also at a certain time.

These sets aren't just grab-bags. They have additional structure. The most fundamental
type of structure they have is that of a \emph{manifold}.\index{manifold} Suppose we start
with a geometrical object such as the real number line, or the Euclidean plane, but
then systematically rob it of all structure relating to measurement, such as distances or angles.
Distances and angles would be \emph{too much} structure for our purposes in this very general context.
For example, there is no meaningful way of stating the angle between two different states
of a helium gas. So we tear out
the information about what's-how-far-from-what, but we retain what's-connected-to-what.
The result is a manifold, which we can think of as a rubber sheet that can be infinitely
stretched or compressed, but not cut or glued together.

As manifolds,
\begin{equation}
  \raisebox{-.13\height}{\includegraphics{ch01/figs/man-eq-small-circle}} = \raisebox{-.2\height}{\includegraphics{ch01/figs/man-eq-large-circle}},
\end{equation}
because without a system of measurement, we can't tell a small circle from a big one.
And without angular measurement, we can't tell that a square has corners,
\begin{equation}
  \raisebox{-.13\height}{\includegraphics{ch01/figs/man-eq-small-circle}} = \raisebox{-.13\height}{\includegraphics{ch01/figs/man-eq-square}}.
\end{equation}
These are one-dimensional manifolds, which we happen to have drawn on a two-dimensional page.
A theorem by Whitney says that it is always \emph{possible} to embed a manifold in some higher-dimensional
space in this way, but such an embedding is optional, not mandatory. If we imagine ourselves as
pointlike beings living in a universe consisting of a circle, then we would consider an hypothetical
second dimension to be nonexistent, because it would never show up in the result of any experiment.

Part of our notion of a manifold is a kind of democratic principle, that no point has special properties
that set it apart from any other point. For example, the figure eight curve
\raisebox{-.13\height}{\includegraphics{ch01/figs/man-figure-eight}} is not a manifold, because its point
of self-intersection is special. If we deleted it, the curve would be broken into two disconnected parts.

We can have manifolds with more than one dimension. For example, the surface of a coffee cup is the
same manifold as the surface of a doughnut,
\begin{equation}
  \raisebox{-.13\height}{\includegraphics{ch01/figs/man-eq-coffee-cup}} = \raisebox{-.13\height}{\includegraphics{ch01/figs/man-eq-doughnut}},
\end{equation}
because one can be transformed into the other by stretching. An $n$-dimensional manifold
is referred to as an $n$-manifold.

\begin{eg}{A robot camera}\label{eg:robot-camera}
Suppose we have a robot consisting of a car that runs along a track, with a rotating camera on a turret.
The state of the robot can be described by a combination of two pieces of data: its position on the track,
and the direction in which the camera points. Taken by themselves, these two parts of the robot's state
define two distinct 1-manifolds: a line and a circle. Taken together, they define a cylinder, which is
a 2-manifold.
\end{eg}

A connected manifold consists of a single piece. A disconnected manifold has multiple blobs that don't
touch. Because it seems that ``nature never jumps,'' physicists normally deal with connected manifolds.

Manifolds are discussed in more detail in section \ref{sec:manifolds}, p.~\pageref{sec:manifolds}.

<% end_sec('continuity-in-nature') %>

<% begin_sec("Vectors in too much generality",nil,'vectors-general') %>

Points in a manifold can be used to represent states, but they can
often also be used to represent changes in state. Examples include displacements along
a line, or rotations on a circle.
The order in which these motions occur may or may not matter.
The robot camera in example \ref{eg:robot-camera} can slide and then rotate, or rotate and then
slide, and the final result is the same state. If a ship sails 100 km north and then 100 km east, the
result is almost the same as going east and then north --- but not quite the same, because of the curvature
of the earth. We want to study the case in which the order doesn't matter, and the motions don't ``wrap
around'' as rotations do. This motivates the following definition.

\begin{important}[Definition of a vector space]
A vector space is a connected manifold that has defined on it an operation of addition
with the following properties:
\begin{enumerate}
\item Addition is commutative, $\vc{a}+\vc{b}=\vc{b}+\vc{a}$.
\item There is no nonzero $\vc{a}$ such that $\vc{a}+\vc{a}=\vc{0}$.
\end{enumerate}
\end{important}
\noindent Addition should also be associative, $(\vc{a}+\vc{b})+\vc{c}=\vc{a}+(\vc{b}+\vc{c})$,
and continuous, and have an identity element $\vc{0}$ and additive inverses.

<% marg() %>
<%
  fig(
    'parallelogram-rule',
    %q{The parallelogram rule used to define vector addition in example \ref{eg:parallelogram-rule}.}
  )
%>
<% end_marg %>

\begin{eg}{The parallelogram rule}\label{eg:parallelogram-rule}
The classic example that most people visualize when they think of a vector space is a space
made of arrows drawn in the euclidean plane. These arrows can be moved around without changing their
identity, as long as we don't rotate them. Addition is defined as shown in figure
\figref{parallelogram-rule}, and the figure makes the commutativity of addition
geometrically obvious. This type of vector, or its generalization to three dimensions, can be
used to describe physical quantities such as displacements (motion from one point to another),
forces, velocities, and magnetic fields.
\end{eg}

We distinguish vectors from variables representing ordinary numbers by
writing them either in bold face, $\vc{x}$, or with some kind of decoration,
called an ``index,'' above and to the right: $x^{\Arrow[.1cm]}$, $x^\star$,
$x^a$, $x^{\smiley}$.  
For compactness, we sometimes use an arrow and move it so
it lines up with the letter, $\vec{x}$. Although the arrow is common, for reasons that will become clear
later we will sometimes want to have more than one kind of decoration to use as an index.

Whenever we have a vector space, there is a natural notion of multiplying a vector by
a number, e.g., $2\vc{v}$ means $\vc{v}+\vc{v}$. By property 2 in the definition of a vector space,
$2\vc{v}$ is not zero unless
$\vc{v}=\vc{0}$.

\begin{eg}{Cutting a vector in half}
Given a vector $\vc{v}$, there is a uniquely defined half-size version $\vc{h}=\vc{v}/2$
defined by $\vc{h}+\vc{h}=\vc{v}$. For suppose
we have some other vector $\vc{i}$ such that $\vc{i}+\vc{i}=\vc{v}$.
Then we can write $(\vc{i}-\vc{h})+(\vc{i}-\vc{h})=\vc{0}$, so by property 2, $\vc{i}-\vc{h}=0$, and
$\vc{i}$ is the same as $\vc{h}$.
\end{eg}

Continuing in this way, we can define $(3/4)\vc{v}$ and so forth, so that multiplication
by any real number is well defined.\footnote{To handle irrational numbers, we can expand our number
as a nonterminating binary decimal, and we will need the completeness
property of manifolds defined on p.~\pageref{manifold-completeness} to ensure that the resulting
limit exists.}

\begin{eg}{Rotations are not vectors}
When we spin the hour on a clock, it doesn't matter whether we rotate it first by one hour and then by two,
or two first and then one, so commutativity is satisfied. But if we do a clockwise rotation by 6 hours
and then followed by another such rotation, the hand is back where it started. This violates
property 2, so rotations don't qualify as vectors. For rotations in more dimensions, commutativity also
fails.
\end{eg}

<% end_sec('vectors-general') %>

<% begin_sec("Measuring vectors by addition",nil,'measuring-vectors-by-addition') %>

The definition of vectors given in section \ref{sec:vectors-general}
is a very general mathematician's definition, and it covers examples
like the vector space of polynomials or a vector space used in economics
to describe how a factory allocates its workers.
Physicists usually use the term to imply a more restrictive
definition, which is vector spaces that in a certain sense have the
same structure as either space (three dimensions) or spacetime (four).
We refer to these as 3-vectors and 4-vectors.

To define ``a certain sense,'' we have to consider what it means to
measure a vector. The qualitative idea is that vectors are
\emph{relational}: whenever we measure a vector, we measure it only in
relation to some measuring device. For example, consider a propeller anemometer, which is
a device like the propeller on an airplane, used to measure the speed of the wind. If the
wind shifts from the north to the south, then the propeller will rotate the opposite way,
and we will say that the wind's velocity vector $\vc{v}$ has changed to $-\vc{v}$. But
exactly the same result is obtained if we use our hand to turn the anemometer around.
The instrument doesn't ``know'' whether it turned around or the wind did. Its measurement
only tells us the direction of the wind \emph{in relation to} its own orientation.

To crystallize this intuition, we make two seemingly weak assumptions about measurement:

\begin{enumerate}\label{measurement-assumptions}
\item We can measure whether a vector is zero.
\item We can physically create the sum of two vectors.
\end{enumerate}

\noindent The idea expressed by assumption 1 is that a zero vector is the only vector we can
measure in absolute terms, rather than in relation to another vector.
Note that, as we'll see in the next section, we cannot in general
determine whether a vector is zero by measuring whether its
\emph{magnitude} is zero. A 4-vector can be nonzero and yet have a nonzero magnitude.

\begin{eg}{Zero magnetic field}\label{eg:zero-magnetic-field}
We can use a magnetic compass with a frictionless bearing to measure
whether a magnetic field is zero. If the field is nonzero, then the needle can be made to oscillate around
its preferred orientation. If the field is zero, then such an oscillation is impossible, and the needle
can only spin at constant speed or stay put if released at rest in an arbitrary orientation.
\end{eg}

<%
 fig(
   'nulling-magnetic-fields',
   %q{Example \ref{eg:nulling-magnetic-fields}.
      Magnetic fields are produced by two solenoids: cylindrical coils of wire with electric currents
      running through them. The solenoids are shown in cross-section,
      with empty space on their interiors and their common axis running right-left. By symmetry, the field
      vectors are along this axis.},
   {
     'width'=>'wide',
     'sidecaption'=>true
   }
 )
%>

\begin{eg}{Strength of a magnetic field}\label{eg:nulling-magnetic-fields}
Figure \figref{nulling-magnetic-fields} shows
a method of measuring how a magnetic field falls off with distance.
Each of the two solenoids produces its own contribution to the field measured at the active tip of the sensor wand.
In such a situation, the fields add as required by assumption 2, and the sensor can tell whether
the field is zero at its own tip. This is similar to example \ref{eg:zero-magnetic-field}, but the
technique is extremely precise because the electronic probe can be used on a very sensitive setting.
If the fixed solenoid produces a magnetic field $\vc{B}$
when unit current flows through it, then increasing the current by a factor $f$ gives
a field $f\vc{B}$. By varying the position $r_m$ of the moving solenoid, and redetermining the value of $f$
that produces zero field, we can find out by what factor the field has changed.
\end{eg}

<% marg(-10) %>
<%
  fig(
    'basis',
    %q{The vectors $\vc{u}$ and $\vc{v}$ form a basis for a plane. Any other vector can be expressed
       as a linear combination of them.}
  )
%>
<% end_marg %>

To make it more clear what is going on here, it is helpful to have the ideas of a linear combination
and a basis. If $\vc{u}$ and $\vc{v}$ are vectors, then for any real numbers $\alpha$ and $\beta$,
the expression $\alpha\vc{u}+\beta\vc{v}$ is called a linear combination of $\vc{u}$ and $\vc{v}$.
If we have a manifold of dimension $n$ that is a vector space, then it is always possible to find
a list of $n$ vectors such that every vector in the space can be expressed as a linear combination of
these vectors. Such a list is called a basis, and the coefficients $\alpha$ and $\beta$ are called
the vector's components in that basis. If this is the first time you've seen these concepts from linear
algebra, then you may want to look at a linear algebra textbook to gain a better \ldots basis in the
subject. I recommend \textbf{Linear Algebra} by Hefferon, which is free online.

<%
 fig(
   'change-of-basis',
   %q{The same vector is expressed in four different choices of basis.},
   {
     'width'=>'wide',
     'sidecaption'=>true,
     'sidepos'=>'b'
   }
 )
%>

A choice of basis is arbitrary. Figure \figref{change-of-basis} shows that when we change our basis,
we get different components. Mathematically, this is just a matter of algebra, e.g., $\vc{c}=-\vc{a}$ and
$\vc{d}=-\vc{b}$, so by substitution $\vc{a}+\vc{b}=-\vc{c}-\vc{d}$. But physically, our assumptions about
measurement imply that we can measure a vector's components, and therefore a change of basis must have
a physical interpretation. If the two dimensions in this example are both spatial rather than temporal,
and the vectors are magnetic field vectors, then the change of basis from $\langle \vc{a},\vc{b} \rangle$
to $\langle \vc{c},\vc{d} \rangle$ is a rotation of two magnetic field detectors by 180\degunit,
$\langle \vc{a},\vc{b} \rangle \rightarrow \langle \vc{e},\vc{f} \rangle$ means cutting the units
of measurement in half, and
$\langle \vc{a},\vc{b} \rangle \rightarrow \langle \vc{g},\vc{h} \rangle$ is accomplished by flipping (reflecting)
the configuration of the detectors.

A physicist thinks of a displacement vector and a magnetic field vector as inhabiting different vector
spaces, because it doesn't make sense to add a displacement to a magnetic field. However, all such
vector spaces are related to one another, because any change of basis in one of them can be related
to a change of basis in another. For example, if a laboratory on the deck of a ship contains magnetic fields
sensors and wind sensors, then rotating the ship by 180\degunit effects the same change of basis for both types
of sensors. This is what a physicist means by a vector, and it is a more restrictive definition than
a mathematician's:

\begin{important}[Definition of vectors and scalars (in physics)]
A 3-vector is a vector that transforms under a change of basis in the same way as a spatial displacement.

\noindent A 4-vector is a vector that transforms under a change of basis in the same way as a spacetime displacement.

\noindent A scalar is a quantity that does not change at all under a change of basis.
\end{important}

<% marg() %>
<%
  fig(
    'vectors-and-scalars',
    %q{Temperature is a scalar. Force is a vector.}
  )
%>
<% end_marg %>

Temperature is a scalar, because a hot cup of coffee doesn't change its temperature
when we turn it around. Force is a vector. When I play tug-of-war with my dog,
her force and mine are the same in strength, but they're in opposite directions.
If we swap positions, our forces reverse their directions, just as an arrow representing a spatial
displacement would.

Consider
a vector representing a displacement in three-dimensional space, visualized abstractly
as an arrow. Assumption 1, that we can tell whether a vector is zero, seems obviously to be satisfied.
But now suppose I drive to Gettysburg, Pennsylvania, and visit the brass plaque marking the site
of the momentous Civil War battle. Am I really in the same spot? The earth has been spinning
and orbiting the sun since 1863.


Motion occurs in spacetime, which is a four-dimensional
manifold. There was an event A, the battle, and an event B, my arrival at the scene.
If A and B are the same point in this four-dimensional space, then I'm there on the day
of the battle, with bullets flying past my head, and it is indisputable that the displacement 4-vector is
zero. But in general we \emph{cannot} tell whether a 4-vector is zero just by examining its spatial part.

When I make observations in four-dimensional spacetime, I also have to
choose a timelike basis vector, call it $\vc{t}$,
such that if the tail of the vector is at an event like the battle of Gettysburg,
its tip is at an event that I consider to occur at the same place but a later time.
This choice of $\vc{t}$ has an element of arbitrariness. An observer in a different state
of motion would make a different choice, as shown in figure \figref{gettysburg}. If we express
the earth's displacement vector in basis $\langle \vc{t},\vc{x} \rangle$, it has both a spatial
component and a temporal component, so we say the the earth moves. If we choose
$\langle \boldsymbol{\tau},\boldsymbol{\xi} \rangle$ instead, then we have effectively chosen
a frame of reference tied to the earth, and we say that the earth's displacement is purely temporal.
<% marg(300) %>
<%
  fig(
    'gettysburg',
    %q{A different choice of basis in spacetime can mean a different definition of what is at rest.}
  )
%>
<% end_marg %>

Because 3-vectors live in a three-dimensional vector space that can be embedded within the four-dimensional
spacetime, a mathematician would consider every 3-vector to be a valid 4-vector. By the physicist's definition,
we reach the opposite conclusion.

An important example of a scalar is the number of ticks on a clock. Since this is just a count,
like the number of apples in a sack, its value can't depend on our choice of basis. We call this
count of the ticks \emph{proper time}, where the word ``proper'' is used in the sense of ``self''
or ``one's own,'' as in ``the Vatican doesn't like in Rome proper.'' This does not, however, mean
that time in general is absolute or independent of our frame of reference --- as we will see
in our study of relativity, time in general is not a scalar. Only proper time is. However, at
velocities too small for relativistic effects to be important, it is a good approximation to think
of time as a scalar, and we can drop the distinction between time and proper time.

When we multiply (or divide) a vector by a scalar, we get another vector (by either the mathematician's definition
or the physicist's). Therefore if we divide a displacement 3-vector by a time (or a proper time,
when the distinction is important), we get a valid 3-vector. In this way, we can define a velocity
vector. Velocity vectors add in relative motion (assumption 2 about measurement on p.~\pageref{measurement-assumptions}).
If object A is moving relative to object B with velocity $\vc{v}_\text{AB}$, and
B relative to C at $\vc{v}_\text{BC}$, then the velocity of A relative to C is given by
\begin{equation}
  \vc{v}_\text{AC} = \vc{v}_\text{AB}+\vc{v}_\text{BC}.
\end{equation}


<% end_sec('measuring-vectors-by-addition') %>



<% begin_hw_sec %>
<% begin_hw('measure-parallelism') %>
Section \ref{sec:measuring-vectors-by-addition}, p.~\pageref{sec:measuring-vectors-by-addition}, states
two assumptions about measurement. Based on these assumptions, can we measure
whether or not two vectors are parallel? Perpendicular?
<% end_hw %>

<% end_hw_sec %>

<% end_chapter %>
